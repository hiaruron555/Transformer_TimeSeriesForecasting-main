{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 1D or 2D array, got 0D array instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 162\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m#np.savetxt('x_test', x_test, delimiter=',', fmt='%f')\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m#np.savetxt('y_test', y_test, delimiter=',', fmt='%f')\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# DataLoaderの作成\u001b[39;00m\n\u001b[1;32m    161\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m create_dataloader(x_train, y_train)\n\u001b[0;32m--> 162\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavetxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain_loader\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%f\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;66;03m#np.savetxt('y_test', y_test, delimiter=',', fmt='%f')\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \n\u001b[1;32m    165\u001b[0m \n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# トレーニングループ\u001b[39;00m\n\u001b[1;32m    167\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/Transformer_TimeSeriesForecasting-main-LRDpDuFD/lib/python3.8/site-packages/numpy/lib/npyio.py:1555\u001b[0m, in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1553\u001b[0m \u001b[38;5;66;03m# Handle 1-dimensional arrays\u001b[39;00m\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1555\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1556\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 1D or 2D array, got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124mD array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m X\u001b[38;5;241m.\u001b[39mndim)\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1558\u001b[0m     \u001b[38;5;66;03m# Common case -- 1d array of numbers\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 1D or 2D array, got 0D array instead"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "from torch.nn import TransformerEncoderLayer, LayerNorm, TransformerEncoder, TransformerDecoderLayer, TransformerDecoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# フラットな手の座標をMediaPipe Handランドマークに変換する関数\n",
    "def flatten_to_landmarks(coordinates):\n",
    "    landmarks = []\n",
    "    for i in range(0, len(coordinates), 3):\n",
    "        landmarks.append((coordinates[i], coordinates[i + 1], coordinates[i + 2]))\n",
    "    return landmarks\n",
    "\n",
    "# データの読み込みと前処理\n",
    "def preprocess_data(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for i in range(len(df) - n_seq):\n",
    "        \"\"\"\"\n",
    "        x_sequence = df.iloc[i:i+n_seq][[f'{j}_{c}' for j in range(num_joints) for c in ['x', 'y', 'z']]].values.flatten()\n",
    "        y_sequence = df.iloc[i+n_seq][[f'{j}_x' for j in range(num_joints)]].values.flatten()\n",
    "        x_data.append(x_sequence)\n",
    "        y_data.append(y_sequence)\n",
    "        \"\"\"\n",
    "        x_sequence = df.iloc[i][[f'{j}_{c}' for j in range(num_joints) for c in ['x', 'y', 'z']]].values.flatten() \n",
    "        x_data.append(x_sequence)\n",
    "        \n",
    "        y_sequence = df.iloc[i+n_seq][[f'{j}_{c}' for j in range(num_joints) for c in ['x', 'y', 'z']]].values.flatten()\n",
    "        y_data.append(y_sequence)\n",
    "\n",
    "    x_data = np.array(x_data, dtype=np.float32)\n",
    "    y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "# DataLoaderの使用\n",
    "def create_dataloader(x_train, y_train):\n",
    "    train_dataset = TensorDataset(torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "# モデルのパラメータ\n",
    "n_seq = 3\n",
    "num_joints = 21\n",
    "#input_size = num_joints * 3 * n_seq  # 各関節の座標 (x, y, z) を持つ\n",
    "input_size = num_joints * 3 \n",
    "hidden_size = 63\n",
    "#output_size = num_joints # すべての関節の x 座標を予測\n",
    "output_size = num_joints * 3\n",
    "num_layers = 4\n",
    "batch_size = 36\n",
    "n_epochs = 100\n",
    "embed_dim = 64\n",
    "n_heads = 3\n",
    "\n",
    "# 位置エンコーディングの定義\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term[:pe[:, 1::2].size(1)])  # Adjust the size for odd d_model\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# モデルに入力するために次元を拡張する\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.tokenConv = nn.Linear(c_in, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x)\n",
    "        return x\n",
    "\n",
    "# Transformerモデルのアーキテクチャ\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, n_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = TokenEmbedding(input_size, hidden_size)\n",
    "        self.positional_encoding = PositionalEncoding(hidden_size)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(hidden_size, n_heads, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        decoder_layer = nn.TransformerDecoderLayer(hidden_size, n_heads)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        memory = self.transformer_encoder(x)\n",
    "        #transformer_output = self.transformer_decoder(x, memory)\n",
    "        #out = self.fc(transformer_output)\n",
    "        out= self.transformer_decoder(x, memory)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# モデル、損失関数、オプティマイザ\n",
    "model = TransformerModel(input_size, hidden_size, output_size, num_layers, n_heads).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(model.parameters())\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.9)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# メインの処理\n",
    "if __name__ == \"__main__\":\n",
    "    # データの読み込みと前処理\n",
    "    #train_csv_path = 'test_10/choki_test_10/choki_test.csv'\n",
    "    train_csv_path = '2_19_hand.csv'\n",
    "    test_csv_path = 'test_10/choki_test_10/choki_test.csv'\n",
    "    \n",
    "    #x_train, y_train = preprocess_data(train_csv_path, n_seq, num_joints)\n",
    "    #x_test, y_test = preprocess_data(test_csv_path, n_seq, num_joints)\n",
    "\n",
    "    x_train, y_train = preprocess_data(train_csv_path)\n",
    "    np.savetxt('x_train_hand', x_train, delimiter=',', fmt='%f')\n",
    "    np.savetxt('y_train_hand', y_train, delimiter=',', fmt='%f')\n",
    "    x_test, y_test = preprocess_data(test_csv_path)\n",
    "    np.savetxt('x_test_hand', x_test, delimiter=',', fmt='%f')\n",
    "    np.savetxt('y_test_hand', y_test, delimiter=',', fmt='%f')\n",
    "\n",
    "    # DataLoaderの作成\n",
    "    train_loader = create_dataloader(x_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    # トレーニングループ\n",
    "    start_time = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.unsqueeze(1).to(device), y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "    #print(f'学習時間: {training_time:.2f} 秒')\n",
    "\n",
    "    # テストデータで評価\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "    #test_outputs = model(torch.tensor(x_test, dtype=torch.float32).unsqueeze(1).to(device))\n",
    "    #test_loss = criterion(test_outputs, torch.tensor(y_test, dtype=torch.float32).to(device))\n",
    "        test_outputs = model(torch.tensor(x_test, dtype=torch.float32).unsqueeze(1).to(device))\n",
    "        test_loss = criterion(test_outputs, torch.tensor(y_test, dtype=torch.float32).to(device))\n",
    "        processing_time_per_image = time.time() - start_time\n",
    "    #print(f'Test Loss: {test_loss.item():.4f}')\n",
    "    #print(f'処理時間_1: {processing_time_per_image:.6f} 秒')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #  3つのテストサンプルごとに予測結果を処理し、1つずつずらして繰り返す\n",
    "    window_size = 3  # ウィンドウサイズ（処理するテストサンプルの数）\n",
    "\n",
    "    for sample_index in range(0, len(x_test)):  # ウィンドウを1つずつずらして処理する\n",
    "    #for sample_index in range(0, len(x_test) - window_size + 1):  # ウィンドウを1つずつずらして処理する\n",
    "        # ウィンドウ内のテストサンプルを取得\n",
    "        x_test_batch = torch.tensor(x_test[sample_index:sample_index+window_size], dtype=torch.float32).unsqueeze(1).to(device)\n",
    "        y_test_batch = torch.tensor(y_test[sample_index:sample_index+window_size], dtype=torch.float32).to(device)\n",
    "        #print(\"y_test_batch:\", y_test_batch)\n",
    "        #np.savetxt('y_test_batch', y_test_batch, delimiter=',', fmt='%f')\n",
    "        print(sample_index+1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 既存のモデルでx_testを予測\n",
    "            start_time = time.time()\n",
    "            #np.savetxt('x_test_batch', x_test_batch, delimiter=',', fmt='%f')\n",
    "            predicted_tensor_x = model(x_test_batch)\n",
    "            #print(\"x_test_batch:\", x_test_batch)\n",
    "            #np.savetxt('predicted_tensor_x', predicted_tensor_x, delimiter=',', fmt='%f')\n",
    "            predicted_x = predicted_tensor_x.cpu().numpy()\n",
    "            processing_time_per_image = time.time() - start_time\n",
    "            #print(f'処理時間_2: {processing_time_per_image:.6f} 秒')\n",
    "\n",
    "            #\"\"\"\n",
    "            # 新しいモデルのインスタンスを作成\n",
    "            new_model = TransformerModel(input_size, hidden_size, output_size, num_layers, n_heads).to(device)\n",
    "            #new_model.load_state_dict(torch.load('your_model.pth'))\n",
    "            #new_model.load_state_dict(torch.load('hanbetu_all.pth'))\n",
    "            new_model.to(device)\n",
    "            new_model.eval()\n",
    "            #\"\"\"\n",
    "\n",
    "            # 既存の手の座標を指定\n",
    "            # 予測結果の後に続く処理\n",
    "            #print(y_test_batch)\n",
    "            ground_truth_landmarks = flatten_to_landmarks(y_test_batch[0])  # 修正\n",
    "            #ground_truth_landmarks = flatten_to_landmarks(y_test_batch[sample_index])\n",
    "            #####print(\"ground_truth_landmarks:\", ground_truth_landmarks)\n",
    "            #print(y_test_batch)\n",
    "            #np.savetxt('ground_truth_landmarks_1', ground_truth_landmarks, delimiter=',', fmt='%f')\n",
    "            truth_landmarks = flatten_to_landmarks(x_test[sample_index])\n",
    "\n",
    "            #print(\"predicted_x:\", predicted_x)\n",
    "            #np.savetxt('predicter.csv', predicted_x, delimiter=',', fmt='%f')\n",
    "            sample_landmarks_x = flatten_to_landmarks(predicted_x[0])  # 予測結果を利用\n",
    "            \n",
    "            \n",
    "            # landmark_0 の x 座標と y 座標の差分を計算し、表示する\n",
    "            x_difference = y_test[sample_index][0] - predicted_x[0][0]\n",
    "            y_difference = y_test[sample_index][1] - predicted_x[0][1]\n",
    "            #print(f'Landmark 0 の x 座標の差分: {x_difference}')\n",
    "            #print(f'Landmark 0 の y 座標の差分: {y_difference}')\n",
    "\n",
    "            # sample_landmarks_xに含まれるすべてのデータを修正してリストに変換\n",
    "            corrected = []\n",
    "            for landmark in sample_landmarks_x:\n",
    "                x_corrected = landmark[0] + x_difference\n",
    "                y_corrected = landmark[1] + y_difference\n",
    "                z_corrected = landmark[2]  # z座標は変更しないと仮定\n",
    "                corrected.append((x_corrected, y_corrected, z_corrected))\n",
    "    \n",
    "            # リストに変換\n",
    "            corrected = [list(landmark) for landmark in corrected]\n",
    "            #print(\"corrected:\", corrected)\n",
    "\n",
    "            \"\"\"\n",
    "            # ground_truth_landmarksとsample_landmarks_xをTensorに変換\n",
    "            #print(\"ground_truth_landmarks:\", ground_truth_landmarks)\n",
    "            ground_truth_tensor = torch.tensor(ground_truth_landmarks, dtype=torch.float32)\n",
    "            #print(\"ground_truth_landmarks:\", ground_truth_landmarks)\n",
    "            sample_landmarks_x_tensor = torch.tensor(sample_landmarks_x, dtype=torch.float32)\n",
    "            # MSELossを計算\n",
    "            loss = criterion(ground_truth_tensor, sample_landmarks_x_tensor)\n",
    "            #print(f'MSE Loss(sample): {loss.item():.4f}')\n",
    "            \n",
    "            \n",
    "            # ground_truth_landmarksとcorrectedをTensorに変換\n",
    "            ground_truth_tensor = torch.tensor(ground_truth_landmarks, dtype=torch.float32)\n",
    "            corrected_tensor = torch.tensor(corrected, dtype=torch.float32)\n",
    "            # MSELossを計算\n",
    "            loss = criterion(ground_truth_tensor, corrected_tensor)\n",
    "            print(f'MSE Loss(corrected): {loss.item():.4f}')\n",
    "\n",
    "            #print(\"sample_landmarks_x_tensor:\", sample_landmarks_x_tensor)\n",
    "            #np.savetxt('sample_landmarks_x_tensor', sample_landmarks_x_tensor, delimiter=',', fmt='%f')\n",
    "            \"\"\"\n",
    "\n",
    "          \n",
    "\n",
    "            # プロットの設定\n",
    "            save_path = f'/home/iwata/Pictures/TF_hand_{sample_index}_n{n_seq}_r_w{window_size}_{n_epochs}.png'\n",
    "            fig, ax = plt.subplots(figsize=(8, 8))\n",
    "            # プロットの範囲を統一\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.set_aspect('equal', 'box')\n",
    "            ax.set_aspect('equal', 'box')\n",
    "\n",
    "            \"\"\"\"\n",
    "            print(\"ground_truth_landmarks:\", ground_truth_landmarks)\n",
    "            np.savetxt('ground_truth_landmarks', ground_truth_landmarks, delimiter=',', fmt='%f')\n",
    "            print(\"corrected:\",corrected)\n",
    "            np.savetxt('corrected', corrected, delimiter=',', fmt='%f')\n",
    "            print(\"truth_landmarks:\", truth_landmarks)\n",
    "            np.savetxt('truth_landmarks', truth_landmarks, delimiter=',', fmt='%f')\n",
    "            \"\"\"\n",
    "\n",
    "            # 手の座標点の順序を指定するリスト（例）\n",
    "            custom_order = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "\n",
    "            #ground_truth_landmarks\n",
    "            max_index = max([max(points) for points in [[0, 1, 2, 3, 4], [0, 5, 6, 7, 8], [5, 9, 10, 11, 12], [9, 13, 14, 15, 16], [13, 17, 18, 19, 20], [0, 17]]])\n",
    "            if max_index < len(ground_truth_landmarks):\n",
    "                for points in [[0, 1, 2, 3, 4], [0, 5, 6, 7, 8], [5, 9, 10, 11, 12], [9, 13, 14, 15, 16], [13, 17, 18, 19, 20], [0, 17]]:\n",
    "                    x_points = [ground_truth_landmarks[i][0] for i in points]\n",
    "                    y_points = [ground_truth_landmarks[i][1] for i in points]\n",
    "                    ax.plot(x_points, y_points, linestyle='-', color='blue', linewidth=2)\n",
    "            else:\n",
    "                print(\"Error: Index out of range in ground_truth_landmarks\")\n",
    "\n",
    "            #corrected\n",
    "            max_index = max([max(points) for points in [[0, 1, 2, 3, 4], [0, 5, 6, 7, 8], [5, 9, 10, 11, 12], [9, 13, 14, 15, 16], [13, 17, 18, 19, 20], [0, 17]]])\n",
    "            if max_index < len(corrected):\n",
    "                for points in [[0, 1, 2, 3, 4], [0, 5, 6, 7, 8], [5, 9, 10, 11, 12], [9, 13, 14, 15, 16], [13, 17, 18, 19, 20], [0, 17]]:\n",
    "                    x_points = [corrected[i][0] for i in points]\n",
    "                    y_points = [corrected[i][1] for i in points]\n",
    "                    ax.plot(x_points, y_points, linestyle='-', color='red', linewidth=2)\n",
    "            else:\n",
    "                print(\"Error: Index out of range in corrected\")\n",
    "\n",
    "            #truth_landmarks\n",
    "            max_index = max([max(points) for points in [[0, 1, 2, 3, 4], [0, 5, 6, 7, 8], [5, 9, 10, 11, 12], [9, 13, 14, 15, 16], [13, 17, 18, 19, 20], [0, 17]]])\n",
    "            if max_index < len(truth_landmarks):\n",
    "                for points in [[0, 1, 2, 3, 4], [0, 5, 6, 7, 8], [5, 9, 10, 11, 12], [9, 13, 14, 15, 16], [13, 17, 18, 19, 20], [0, 17]]:\n",
    "                    x_points = [truth_landmarks[i][0] for i in points]\n",
    "                    y_points = [truth_landmarks[i][1] for i in points]\n",
    "                    ax.plot(x_points, y_points, linestyle='-', color='green', linewidth=2)\n",
    "            else:\n",
    "                print(\"Error: Index out of range in truth_landmarks\")\n",
    "\n",
    "            #plt.legend()\n",
    "            print('aaa')\n",
    "            # 画像を保存\n",
    "            plt.savefig(save_path)\n",
    "\n",
    "            # 画像を表示\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer_TimeSeriesForecasting-main-LRDpDuFD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
