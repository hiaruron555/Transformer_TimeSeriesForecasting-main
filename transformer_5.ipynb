{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "モデルのトレーニングと評価を開始します\n",
      "x_data shape: [[ 3.0177763e-01  2.4015088e-01 -2.7078192e-07 ...  3.0410638e-01\n",
      "   1.5981619e-01 -2.0553696e-03]\n",
      " [ 3.0656013e-01  2.4495441e-01 -2.5619059e-07 ...  3.0713192e-01\n",
      "   1.5847611e-01 -4.0791878e-03]\n",
      " [ 3.1721818e-01  2.5477961e-01 -2.6701744e-07 ...  3.1561422e-01\n",
      "   1.6034269e-01 -9.4832713e-03]\n",
      " ...\n",
      " [ 4.6558216e-01  7.3515630e-01 -2.8816527e-07 ...  3.6690935e-01\n",
      "   6.9051850e-01 -2.6442751e-02]\n",
      " [ 4.6589616e-01  7.3482531e-01 -2.8830510e-07 ...  3.6778682e-01\n",
      "   6.8758488e-01 -2.9284025e-02]\n",
      " [ 4.6522781e-01  7.3406971e-01 -2.9774691e-07 ...  3.6846039e-01\n",
      "   6.8640077e-01 -3.0148054e-02]]\n",
      "y_data shape: [[ 3.3908221e-01  2.6326287e-01 -2.3698144e-07 ...  3.3783907e-01\n",
      "   1.7542464e-01 -1.2146754e-02]\n",
      " [ 3.6470985e-01  2.8531140e-01 -2.0371067e-07 ...  3.8092110e-01\n",
      "   1.9574982e-01 -9.5270742e-03]\n",
      " [ 3.6785933e-01  2.8284615e-01 -1.2312549e-07 ...  3.4842935e-01\n",
      "   1.7544371e-01 -7.7137109e-03]\n",
      " ...\n",
      " [ 4.6483582e-01  7.3452824e-01 -2.9150294e-07 ...  3.6693296e-01\n",
      "   6.8705958e-01 -2.7759884e-02]\n",
      " [ 4.6452594e-01  7.3414916e-01 -2.9596100e-07 ...  3.6637518e-01\n",
      "   6.8853599e-01 -2.7204711e-02]\n",
      " [ 4.6361893e-01  7.3240328e-01 -3.0708475e-07 ...  3.6571077e-01\n",
      "   6.8593168e-01 -2.9215068e-02]]\n",
      "x_data shape: [[ 7.64129400e-01  3.69316399e-01 -3.78357896e-07  8.18990886e-01\n",
      "   3.04971278e-01 -7.13253906e-03  8.57148349e-01  2.22828507e-01\n",
      "  -7.89297186e-03  8.62963319e-01  1.38269305e-01 -1.19689163e-02\n",
      "   8.34078908e-01  1.07650772e-01 -1.49062062e-02  8.19615126e-01\n",
      "   1.62030086e-01  1.32133914e-02  8.30829859e-01  9.65445340e-02\n",
      "  -4.61492082e-03  8.33229721e-01  1.50663540e-01 -1.60651393e-02\n",
      "   8.27250898e-01  1.86579645e-01 -2.06866991e-02  7.91378796e-01\n",
      "   1.62563249e-01  8.74017738e-03  8.05239797e-01  1.03304364e-01\n",
      "  -1.28009096e-02  8.06317568e-01  1.81136206e-01 -2.04040930e-02\n",
      "   7.97225416e-01  2.18318954e-01 -1.97533891e-02  7.62239218e-01\n",
      "   1.69703364e-01  6.59710786e-04  7.77574658e-01  1.10860303e-01\n",
      "  -2.44420655e-02  7.80596077e-01  1.88866615e-01 -2.10258886e-02\n",
      "   7.72011995e-01  2.29435161e-01 -1.09741762e-02  7.28487372e-01\n",
      "   1.83685318e-01 -7.73478951e-03  7.46088386e-01  1.25571877e-01\n",
      "  -2.17651613e-02  7.54826903e-01  1.75250277e-01 -1.35427872e-02\n",
      "   7.50757873e-01  2.10987151e-01 -3.02341348e-03]\n",
      " [ 7.49798656e-01  3.76767337e-01 -3.77550037e-07  8.04364443e-01\n",
      "   3.07835877e-01 -6.07547630e-03  8.39428782e-01  2.25882143e-01\n",
      "  -5.75095788e-03  8.41555715e-01  1.45524189e-01 -8.88973381e-03\n",
      "   8.15648973e-01  1.11159332e-01 -1.10549172e-02  8.07628572e-01\n",
      "   1.71241894e-01  1.63329951e-02  8.12695503e-01  1.04767285e-01\n",
      "  -7.41777476e-04  8.14156950e-01  1.54876426e-01 -1.30015733e-02\n",
      "   8.10535371e-01  1.94943428e-01 -1.79819595e-02  7.77708054e-01\n",
      "   1.72433585e-01  1.22835580e-02  7.85275578e-01  1.11162663e-01\n",
      "  -7.71058258e-03  7.86615074e-01  1.84905127e-01 -1.60686914e-02\n",
      "   7.81045735e-01  2.28011101e-01 -1.58291087e-02  7.47613013e-01\n",
      "   1.80284411e-01  4.61644819e-03  7.57317185e-01  1.23541184e-01\n",
      "  -1.78102925e-02  7.60578096e-01  1.96799085e-01 -1.51257496e-02\n",
      "   7.55754173e-01  2.40890235e-01 -5.88925229e-03  7.14541614e-01\n",
      "   1.94795474e-01 -3.41555593e-03  7.25843430e-01  1.37433663e-01\n",
      "  -1.51058733e-02  7.33626604e-01  1.84067160e-01 -7.11250026e-03\n",
      "   7.32132077e-01  2.20658004e-01  3.04804184e-03]\n",
      " [ 7.24605501e-01  3.94901812e-01 -3.35405645e-07  7.78001070e-01\n",
      "   3.23833585e-01 -7.61455670e-03  8.11518550e-01  2.38072336e-01\n",
      "  -7.72799691e-03  8.13417792e-01  1.54965416e-01 -1.07347341e-02\n",
      "   7.85834610e-01  1.25886947e-01 -1.27001507e-02  7.75374353e-01\n",
      "   1.89448521e-01  1.24976756e-02  7.77255237e-01  1.22066721e-01\n",
      "  -5.48240682e-03  7.81262815e-01  1.70135587e-01 -1.82285625e-02\n",
      "   7.79698372e-01  2.11682409e-01 -2.32507624e-02  7.46120155e-01\n",
      "   1.94533899e-01  9.37212911e-03  7.50299156e-01  1.32704988e-01\n",
      "  -1.17037538e-02  7.55358517e-01  2.03194886e-01 -2.07576361e-02\n",
      "   7.52381504e-01  2.49001205e-01 -2.08671317e-02  7.16725886e-01\n",
      "   2.06052944e-01  2.68874108e-03  7.22247183e-01  1.49260685e-01\n",
      "  -1.96034629e-02  7.29298532e-01  2.16444805e-01 -1.82581022e-02\n",
      "   7.27559924e-01  2.62530506e-01 -1.00376895e-02  6.84072435e-01\n",
      "   2.24028930e-01 -4.56258887e-03  6.90735638e-01  1.68110088e-01\n",
      "  -1.64210536e-02  7.01854229e-01  2.06314594e-01 -1.03731239e-02\n",
      "   7.04007745e-01  2.42278576e-01 -1.64923596e-03]\n",
      " [ 6.98243082e-01  4.27390307e-01 -3.97958161e-07  7.45532990e-01\n",
      "   3.44016939e-01 -5.75917447e-03  7.69789457e-01  2.52547503e-01\n",
      "  -6.31257985e-03  7.68110693e-01  1.70239449e-01 -1.03363022e-02\n",
      "   7.40965128e-01  1.42281562e-01 -1.27440523e-02  7.32314110e-01\n",
      "   1.99999347e-01  1.07185198e-02  7.31221139e-01  1.28058195e-01\n",
      "  -7.55841052e-03  7.38067210e-01  1.82531759e-01 -1.97080616e-02\n",
      "   7.38203347e-01  2.25337029e-01 -2.44603790e-02  7.04940915e-01\n",
      "   2.11192757e-01  6.30252389e-03  7.06725419e-01  1.54531345e-01\n",
      "  -1.30216032e-02  7.15790391e-01  2.23602816e-01 -2.03184728e-02\n",
      "   7.14082658e-01  2.63447434e-01 -2.07347553e-02  6.77842438e-01\n",
      "   2.28466883e-01 -1.48892880e-03  6.82236433e-01  1.72489598e-01\n",
      "  -2.19464414e-02  6.92920446e-01  2.39514783e-01 -1.80913247e-02\n",
      "   6.92449689e-01  2.82938302e-01 -9.55511536e-03  6.48190320e-01\n",
      "   2.51616269e-01 -9.91586968e-03  6.56934202e-01  1.92778006e-01\n",
      "  -2.04380248e-02  6.67556047e-01  2.31502324e-01 -1.25991479e-02\n",
      "   6.67376399e-01  2.66523451e-01 -3.28257750e-03]\n",
      " [ 6.62426293e-01  4.55497384e-01 -3.33946161e-07  7.04212844e-01\n",
      "   3.65090549e-01 -5.05739031e-03  7.23537803e-01  2.70803601e-01\n",
      "  -5.91633469e-03  7.16319501e-01  1.91174403e-01 -1.03408815e-02\n",
      "   6.88974023e-01  1.62310973e-01 -1.34095429e-02  6.82572782e-01\n",
      "   2.22724229e-01  1.02504222e-02  6.77431107e-01  1.51736543e-01\n",
      "  -8.63887370e-03  6.89113379e-01  2.02317894e-01 -2.21700482e-02\n",
      "   6.92998767e-01  2.49217495e-01 -2.78890599e-02  6.56800151e-01\n",
      "   2.41328642e-01  4.73205047e-03  6.52389467e-01  1.77398652e-01\n",
      "  -1.60614979e-02  6.67852938e-01  2.40440518e-01 -2.58602351e-02\n",
      "   6.71217144e-01  2.86328822e-01 -2.75987964e-02  6.31399095e-01\n",
      "   2.67223567e-01 -3.91393388e-03  6.32073760e-01  2.12334991e-01\n",
      "  -2.55033299e-02  6.49283886e-01  2.71903068e-01 -2.39638500e-02\n",
      "   6.53750479e-01  3.16894829e-01 -1.66411344e-02  6.03483677e-01\n",
      "   2.99456835e-01 -1.31227821e-02  6.04773998e-01  2.41057038e-01\n",
      "  -2.53559649e-02  6.21238589e-01  2.69649237e-01 -1.95803512e-02\n",
      "   6.27959073e-01  3.01576674e-01 -1.15468269e-02]\n",
      " [ 6.24077082e-01  4.98975277e-01 -1.85265748e-07  6.56069100e-01\n",
      "   3.94566387e-01 -3.53943789e-03  6.61211073e-01  2.90762514e-01\n",
      "  -3.08574480e-03  6.44958794e-01  2.14156568e-01 -6.92217844e-03\n",
      "   6.13881230e-01  1.98144555e-01 -1.07713239e-02  6.22009754e-01\n",
      "   2.61905968e-01  1.47315096e-02  6.08714283e-01  1.88060418e-01\n",
      "  -3.95170227e-03  6.22208714e-01  2.01748878e-01 -1.85304079e-02\n",
      "   6.35159016e-01  2.42405757e-01 -2.44679544e-02  5.98297775e-01\n",
      "   2.89537042e-01  8.27485137e-03  5.84424317e-01  2.12700263e-01\n",
      "  -1.21549629e-02  6.04676962e-01  2.55546600e-01 -2.36006621e-02\n",
      "   6.17304683e-01  3.06954473e-01 -2.52630226e-02  5.75129747e-01\n",
      "   3.26019317e-01 -1.29073602e-03  5.70065081e-01  2.66724467e-01\n",
      "  -2.51705796e-02  5.91808736e-01  3.16896170e-01 -2.58309841e-02\n",
      "   6.02044225e-01  3.66029233e-01 -1.82409398e-02  5.50519764e-01\n",
      "   3.71587485e-01 -1.10619711e-02  5.47680318e-01  3.08274627e-01\n",
      "  -2.55097002e-02  5.69006801e-01  3.27525228e-01 -2.03129686e-02\n",
      "   5.80323815e-01  3.58316720e-01 -1.18075861e-02]\n",
      " [ 5.87488174e-01  5.45485795e-01  1.10124525e-07  6.03522182e-01\n",
      "   4.41809088e-01 -3.83726787e-03  5.94329357e-01  3.36141557e-01\n",
      "  -1.98688940e-03  5.76643586e-01  2.70209879e-01 -4.23966162e-03\n",
      "   5.52680016e-01  2.36828044e-01 -6.33536140e-03  5.53364754e-01\n",
      "   3.15329343e-01  1.03630032e-02  5.29106915e-01  2.35810891e-01\n",
      "  -9.36997123e-03  5.44088066e-01  2.16529533e-01 -2.35854872e-02\n",
      "   5.65504432e-01  2.35439390e-01 -2.78345123e-02  5.31870067e-01\n",
      "   3.45110118e-01  3.51436320e-03  5.00993550e-01  2.54566193e-01\n",
      "  -1.40236504e-02  5.24365723e-01  2.50028789e-01 -2.37091277e-02\n",
      "   5.48753500e-01  2.73545504e-01 -2.46476065e-02  5.12431622e-01\n",
      "   3.89948279e-01 -6.49119169e-03  5.05505919e-01  3.32351416e-01\n",
      "  -2.96648424e-02  5.33169270e-01  3.70952636e-01 -3.10287010e-02\n",
      "   5.49234569e-01  4.11497623e-01 -2.34609228e-02  4.95261461e-01\n",
      "   4.45664018e-01 -1.67503562e-02  4.85257000e-01  3.84897768e-01\n",
      "  -3.11237648e-02  5.10945678e-01  3.95916373e-01 -2.55743917e-02\n",
      "   5.29320538e-01  4.22550768e-01 -1.62121095e-02]\n",
      " [ 5.53833961e-01  5.95260739e-01  2.25393052e-07  5.61096430e-01\n",
      "   4.98558074e-01 -1.17922351e-02  5.40086031e-01  4.03553188e-01\n",
      "  -1.44417305e-02  5.04347146e-01  3.47400367e-01 -1.91113893e-02\n",
      "   4.67356205e-01  3.28904539e-01 -2.26191524e-02  5.03713250e-01\n",
      "   3.62623513e-01  5.37700951e-03  4.85906839e-01  2.81199604e-01\n",
      "  -1.36452476e-02  4.77964908e-01  2.40077212e-01 -2.50732545e-02\n",
      "   4.79337543e-01  2.30664253e-01 -2.82054506e-02  4.77939039e-01\n",
      "   3.96437734e-01  1.46122853e-04  4.29509401e-01  3.09524447e-01\n",
      "  -1.89218577e-02  4.31075364e-01  2.73458481e-01 -2.64583584e-02\n",
      "   4.40469474e-01  2.58687675e-01 -2.53208317e-02  4.59507585e-01\n",
      "   4.50610727e-01 -8.80839862e-03  4.44131166e-01  3.96231055e-01\n",
      "  -4.05028686e-02  4.81415391e-01  4.26789671e-01 -4.12985310e-02\n",
      "   5.05063593e-01  4.60332453e-01 -3.02137565e-02  4.46039200e-01\n",
      "   5.15259624e-01 -1.79882478e-02  4.34195995e-01  4.66481745e-01\n",
      "  -4.05436419e-02  4.63457286e-01  4.76538897e-01 -3.51438299e-02\n",
      "   4.82766658e-01  4.96744424e-01 -2.38801185e-02]]\n",
      "y_data shape: [[ 6.98243082e-01  4.27390307e-01 -3.97958161e-07  7.45532990e-01\n",
      "   3.44016939e-01 -5.75917447e-03  7.69789457e-01  2.52547503e-01\n",
      "  -6.31257985e-03  7.68110693e-01  1.70239449e-01 -1.03363022e-02\n",
      "   7.40965128e-01  1.42281562e-01 -1.27440523e-02  7.32314110e-01\n",
      "   1.99999347e-01  1.07185198e-02  7.31221139e-01  1.28058195e-01\n",
      "  -7.55841052e-03  7.38067210e-01  1.82531759e-01 -1.97080616e-02\n",
      "   7.38203347e-01  2.25337029e-01 -2.44603790e-02  7.04940915e-01\n",
      "   2.11192757e-01  6.30252389e-03  7.06725419e-01  1.54531345e-01\n",
      "  -1.30216032e-02  7.15790391e-01  2.23602816e-01 -2.03184728e-02\n",
      "   7.14082658e-01  2.63447434e-01 -2.07347553e-02  6.77842438e-01\n",
      "   2.28466883e-01 -1.48892880e-03  6.82236433e-01  1.72489598e-01\n",
      "  -2.19464414e-02  6.92920446e-01  2.39514783e-01 -1.80913247e-02\n",
      "   6.92449689e-01  2.82938302e-01 -9.55511536e-03  6.48190320e-01\n",
      "   2.51616269e-01 -9.91586968e-03  6.56934202e-01  1.92778006e-01\n",
      "  -2.04380248e-02  6.67556047e-01  2.31502324e-01 -1.25991479e-02\n",
      "   6.67376399e-01  2.66523451e-01 -3.28257750e-03]\n",
      " [ 6.62426293e-01  4.55497384e-01 -3.33946161e-07  7.04212844e-01\n",
      "   3.65090549e-01 -5.05739031e-03  7.23537803e-01  2.70803601e-01\n",
      "  -5.91633469e-03  7.16319501e-01  1.91174403e-01 -1.03408815e-02\n",
      "   6.88974023e-01  1.62310973e-01 -1.34095429e-02  6.82572782e-01\n",
      "   2.22724229e-01  1.02504222e-02  6.77431107e-01  1.51736543e-01\n",
      "  -8.63887370e-03  6.89113379e-01  2.02317894e-01 -2.21700482e-02\n",
      "   6.92998767e-01  2.49217495e-01 -2.78890599e-02  6.56800151e-01\n",
      "   2.41328642e-01  4.73205047e-03  6.52389467e-01  1.77398652e-01\n",
      "  -1.60614979e-02  6.67852938e-01  2.40440518e-01 -2.58602351e-02\n",
      "   6.71217144e-01  2.86328822e-01 -2.75987964e-02  6.31399095e-01\n",
      "   2.67223567e-01 -3.91393388e-03  6.32073760e-01  2.12334991e-01\n",
      "  -2.55033299e-02  6.49283886e-01  2.71903068e-01 -2.39638500e-02\n",
      "   6.53750479e-01  3.16894829e-01 -1.66411344e-02  6.03483677e-01\n",
      "   2.99456835e-01 -1.31227821e-02  6.04773998e-01  2.41057038e-01\n",
      "  -2.53559649e-02  6.21238589e-01  2.69649237e-01 -1.95803512e-02\n",
      "   6.27959073e-01  3.01576674e-01 -1.15468269e-02]\n",
      " [ 6.24077082e-01  4.98975277e-01 -1.85265748e-07  6.56069100e-01\n",
      "   3.94566387e-01 -3.53943789e-03  6.61211073e-01  2.90762514e-01\n",
      "  -3.08574480e-03  6.44958794e-01  2.14156568e-01 -6.92217844e-03\n",
      "   6.13881230e-01  1.98144555e-01 -1.07713239e-02  6.22009754e-01\n",
      "   2.61905968e-01  1.47315096e-02  6.08714283e-01  1.88060418e-01\n",
      "  -3.95170227e-03  6.22208714e-01  2.01748878e-01 -1.85304079e-02\n",
      "   6.35159016e-01  2.42405757e-01 -2.44679544e-02  5.98297775e-01\n",
      "   2.89537042e-01  8.27485137e-03  5.84424317e-01  2.12700263e-01\n",
      "  -1.21549629e-02  6.04676962e-01  2.55546600e-01 -2.36006621e-02\n",
      "   6.17304683e-01  3.06954473e-01 -2.52630226e-02  5.75129747e-01\n",
      "   3.26019317e-01 -1.29073602e-03  5.70065081e-01  2.66724467e-01\n",
      "  -2.51705796e-02  5.91808736e-01  3.16896170e-01 -2.58309841e-02\n",
      "   6.02044225e-01  3.66029233e-01 -1.82409398e-02  5.50519764e-01\n",
      "   3.71587485e-01 -1.10619711e-02  5.47680318e-01  3.08274627e-01\n",
      "  -2.55097002e-02  5.69006801e-01  3.27525228e-01 -2.03129686e-02\n",
      "   5.80323815e-01  3.58316720e-01 -1.18075861e-02]\n",
      " [ 5.87488174e-01  5.45485795e-01  1.10124525e-07  6.03522182e-01\n",
      "   4.41809088e-01 -3.83726787e-03  5.94329357e-01  3.36141557e-01\n",
      "  -1.98688940e-03  5.76643586e-01  2.70209879e-01 -4.23966162e-03\n",
      "   5.52680016e-01  2.36828044e-01 -6.33536140e-03  5.53364754e-01\n",
      "   3.15329343e-01  1.03630032e-02  5.29106915e-01  2.35810891e-01\n",
      "  -9.36997123e-03  5.44088066e-01  2.16529533e-01 -2.35854872e-02\n",
      "   5.65504432e-01  2.35439390e-01 -2.78345123e-02  5.31870067e-01\n",
      "   3.45110118e-01  3.51436320e-03  5.00993550e-01  2.54566193e-01\n",
      "  -1.40236504e-02  5.24365723e-01  2.50028789e-01 -2.37091277e-02\n",
      "   5.48753500e-01  2.73545504e-01 -2.46476065e-02  5.12431622e-01\n",
      "   3.89948279e-01 -6.49119169e-03  5.05505919e-01  3.32351416e-01\n",
      "  -2.96648424e-02  5.33169270e-01  3.70952636e-01 -3.10287010e-02\n",
      "   5.49234569e-01  4.11497623e-01 -2.34609228e-02  4.95261461e-01\n",
      "   4.45664018e-01 -1.67503562e-02  4.85257000e-01  3.84897768e-01\n",
      "  -3.11237648e-02  5.10945678e-01  3.95916373e-01 -2.55743917e-02\n",
      "   5.29320538e-01  4.22550768e-01 -1.62121095e-02]\n",
      " [ 5.53833961e-01  5.95260739e-01  2.25393052e-07  5.61096430e-01\n",
      "   4.98558074e-01 -1.17922351e-02  5.40086031e-01  4.03553188e-01\n",
      "  -1.44417305e-02  5.04347146e-01  3.47400367e-01 -1.91113893e-02\n",
      "   4.67356205e-01  3.28904539e-01 -2.26191524e-02  5.03713250e-01\n",
      "   3.62623513e-01  5.37700951e-03  4.85906839e-01  2.81199604e-01\n",
      "  -1.36452476e-02  4.77964908e-01  2.40077212e-01 -2.50732545e-02\n",
      "   4.79337543e-01  2.30664253e-01 -2.82054506e-02  4.77939039e-01\n",
      "   3.96437734e-01  1.46122853e-04  4.29509401e-01  3.09524447e-01\n",
      "  -1.89218577e-02  4.31075364e-01  2.73458481e-01 -2.64583584e-02\n",
      "   4.40469474e-01  2.58687675e-01 -2.53208317e-02  4.59507585e-01\n",
      "   4.50610727e-01 -8.80839862e-03  4.44131166e-01  3.96231055e-01\n",
      "  -4.05028686e-02  4.81415391e-01  4.26789671e-01 -4.12985310e-02\n",
      "   5.05063593e-01  4.60332453e-01 -3.02137565e-02  4.46039200e-01\n",
      "   5.15259624e-01 -1.79882478e-02  4.34195995e-01  4.66481745e-01\n",
      "  -4.05436419e-02  4.63457286e-01  4.76538897e-01 -3.51438299e-02\n",
      "   4.82766658e-01  4.96744424e-01 -2.38801185e-02]\n",
      " [ 5.20187020e-01  6.56985104e-01  2.76233806e-07  5.18445671e-01\n",
      "   5.46429038e-01 -1.60848442e-02  4.93882298e-01  4.67881173e-01\n",
      "  -1.96377039e-02  4.50405985e-01  4.24650818e-01 -2.41343919e-02\n",
      "   4.12248135e-01  4.39774156e-01 -2.70747039e-02  4.58002150e-01\n",
      "   4.24624920e-01  1.36077707e-03  4.33450669e-01  3.31343830e-01\n",
      "  -6.53056893e-03  4.17048872e-01  2.82449126e-01 -1.16668250e-02\n",
      "   4.02056068e-01  2.45165333e-01 -1.52508775e-02  4.28668380e-01\n",
      "   4.61543828e-01 -2.54932296e-04  3.78758967e-01  3.91899705e-01\n",
      "  -1.59494914e-02  3.53722453e-01  3.48999232e-01 -2.56305244e-02\n",
      "   3.35196793e-01  3.15270752e-01 -2.96520852e-02  4.13014799e-01\n",
      "   5.14971256e-01 -4.38502058e-03  3.92345876e-01  4.68427211e-01\n",
      "  -3.01405936e-02  4.29418266e-01  4.98665929e-01 -3.29108499e-02\n",
      "   4.52608436e-01  5.28224170e-01 -2.56950893e-02  4.03976232e-01\n",
      "   5.79913735e-01 -9.44251195e-03  3.84280741e-01  5.33626258e-01\n",
      "  -2.95737516e-02  4.12958592e-01  5.39221942e-01 -2.75693256e-02\n",
      "   4.36705768e-01  5.55045843e-01 -2.03027725e-02]\n",
      " [ 4.98201966e-01  6.96851373e-01  3.33813233e-07  4.96389180e-01\n",
      "   5.98797023e-01 -2.29964573e-02  4.62855935e-01  5.14599979e-01\n",
      "  -2.79958677e-02  4.10659790e-01  4.90690947e-01 -3.23717557e-02\n",
      "   3.71765494e-01  5.16281545e-01 -3.52404863e-02  4.20564353e-01\n",
      "   4.69153285e-01 -5.40325884e-03  3.86785716e-01  3.78514856e-01\n",
      "  -1.34919425e-02  3.66500109e-01  3.28547388e-01 -1.87047645e-02\n",
      "   3.46974313e-01  2.89917707e-01 -2.21207328e-02  3.93633097e-01\n",
      "   5.15673816e-01 -5.37376851e-03  3.34175646e-01  4.54441994e-01\n",
      "  -1.83104593e-02  3.02208632e-01  4.19494838e-01 -2.76233125e-02\n",
      "   2.72838652e-01  3.93920481e-01 -3.13165337e-02  3.82488102e-01\n",
      "   5.76150417e-01 -8.20835773e-03  3.57992232e-01  5.39697349e-01\n",
      "  -3.55167650e-02  3.97088230e-01  5.57680428e-01 -3.95721011e-02\n",
      "   4.19194311e-01  5.81447542e-01 -3.22871208e-02  3.78076464e-01\n",
      "   6.44963682e-01 -1.23176873e-02  3.50493371e-01  6.02086782e-01\n",
      "  -3.26939896e-02  3.80281776e-01  6.02142751e-01 -2.85799094e-02\n",
      "   4.04491395e-01  6.15306675e-01 -1.93706062e-02]\n",
      " [ 4.80275989e-01  7.25478351e-01  3.80243279e-07  4.73599970e-01\n",
      "   6.23190403e-01 -1.96974799e-02  4.36934561e-01  5.47404706e-01\n",
      "  -2.47135609e-02  3.84484947e-01  5.35586476e-01 -2.96456050e-02\n",
      "   3.46450776e-01  5.67529321e-01 -3.37175429e-02  4.00882214e-01\n",
      "   5.04211962e-01 -8.31190217e-03  3.63032728e-01  4.14487004e-01\n",
      "  -1.69329178e-02  3.41388673e-01  3.67357939e-01 -2.27015465e-02\n",
      "   3.19461048e-01  3.26446474e-01 -2.68765073e-02  3.74184817e-01\n",
      "   5.52142501e-01 -9.09419544e-03  3.14049602e-01  5.00789642e-01\n",
      "  -2.51154099e-02  2.78050482e-01  4.69458133e-01 -3.73454951e-02\n",
      "   2.44617969e-01  4.45084840e-01 -4.33098003e-02  3.64937276e-01\n",
      "   6.13541722e-01 -1.12623954e-02  3.35877150e-01  5.85984230e-01\n",
      "  -3.93357612e-02  3.77287984e-01  6.02050006e-01 -4.29468565e-02\n",
      "   4.02675807e-01  6.24022603e-01 -3.54806595e-02  3.63819242e-01\n",
      "   6.83002770e-01 -1.41768120e-02  3.32500964e-01  6.47758305e-01\n",
      "  -3.51915248e-02  3.61621290e-01  6.45455718e-01 -3.03664077e-02\n",
      "   3.86189193e-01  6.55075967e-01 -2.05091089e-02]]\n",
      "seq_len: 36\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 292\u001b[0m\n\u001b[1;32m    290\u001b[0m valid_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     loss_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_provider\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m8_x\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     loss_valid \u001b[38;5;241m=\u001b[39m evaluate(flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, data_provider\u001b[38;5;241m=\u001b[39mdata_provider(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, src_len, tgt_len, batch_size, feature\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m8_x\u001b[39m\u001b[38;5;124m'\u001b[39m), criterion\u001b[38;5;241m=\u001b[39mcriterion)\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m epoch \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[13], line 190\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data_provider, optimizer, criterion)\u001b[0m\n\u001b[1;32m    188\u001b[0m input_tgt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x_tarain[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:,:],y_tarain[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    189\u001b[0m mask_x, mask_y \u001b[38;5;241m=\u001b[39m create_mask(x_tarain, input_tgt)\n\u001b[0;32m--> 190\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x_tarain\u001b[38;5;241m=\u001b[39my_tarain, y_tarain\u001b[38;5;241m=\u001b[39m\u001b[43minput_y\u001b[49m, mask_src\u001b[38;5;241m=\u001b[39mmask_x, mask_tgt\u001b[38;5;241m=\u001b[39mmask_y)\n\u001b[1;32m    191\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    192\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y_tarain)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_y' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import LayerNorm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerDecoder, TransformerEncoderLayer, TransformerDecoderLayer\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# デバイスの設定\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# フラットな手の座標をMediaPipe Handランドマークに変換する関数\n",
    "def flatten_to_landmarks(coordinates):\n",
    "    landmarks = []\n",
    "    for i in range(0, len(coordinates), 3):\n",
    "        landmarks.append((coordinates[i], coordinates[i + 1], coordinates[i + 2]))\n",
    "    return landmarks\n",
    "\n",
    "# データの読み込みと前処理\n",
    "# データの読み込みと前処理\n",
    "def preprocess_data(csv_path, n_seq, num_joints):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for i in range(len(df) - n_seq):\n",
    "        x_sequence = df.iloc[i:i+n_seq][[f'{j}_{c}' for j in range(num_joints) for c in ['x', 'y', 'z']]].values.flatten()\n",
    "        x_data.append(x_sequence)\n",
    "\n",
    "        y_sequence = df.iloc[i+n_seq][[f'{j}_{c}' for j in range(num_joints) for c in ['x', 'y', 'z']]].values.flatten()\n",
    "        y_data.append(y_sequence)\n",
    "\n",
    "    x_data = np.array(x_data, dtype=np.float32)\n",
    "    y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "    # 形状を修正：[サンプル数, シーケンス長, 特徴量数]に変換\n",
    "    #x_data = x_data.reshape((-1, n_seq, num_joints * 3))\n",
    "    #y_data = y_data.reshape((-1, num_joints * 3))\n",
    "\n",
    "    return x_data, y_data\n",
    "\n",
    "# じゃんけんの手のラベル\n",
    "janken_labels = {0: 'チョキ', 1: 'グー', 2: 'パー'}\n",
    "\n",
    "# DataLoaderの使用\n",
    "def create_dataloader(x_train, y_train, batch_size):\n",
    "    train_dataset = TensorDataset(torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.float32))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "\n",
    "# 位置エンコーディングの定義\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "# モデルに入力するために次元を拡張する\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.tokenConv = nn.Linear(c_in, d_model) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x)\n",
    "        return x\n",
    "\n",
    "# Transformerの定義\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers, num_decoder_layers, d_model, d_input, d_output, dim_feedforward=512, dropout=0.1, nhead=8):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.token_embedding_x_data = TokenEmbedding(d_input, d_model)\n",
    "        self.token_embedding_y_data = TokenEmbedding(d_output, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=dropout)\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True, activation='gelu')\n",
    "        encoder_norm = LayerNorm(d_model)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers=num_encoder_layers, norm=encoder_norm)\n",
    "        decoder_layer = TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=True, activation='gelu')\n",
    "        decoder_norm = LayerNorm(d_model)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers, norm=decoder_norm)\n",
    "        self.output = nn.Linear(d_model, d_output)\n",
    "\n",
    "    def forward(self, x_data, y_data, mask_x_data, mask_y_data):\n",
    "        print(f\"x_data shape: {x_data.shape}\")  # デバッグ用：x_dataの形状をプリント\n",
    "        print(f\"y_data shape: {y_data.shape}\")  # デバッグ用：y_dataの形状をプリント\n",
    "\n",
    "        embedding_x_data = self.positional_encoding(self.token_embedding_x_data(x_data))\n",
    "        print(f\"embedding_x_data shape: {embedding_x_data.shape}\")  # デバッグ用：embedding_x_dataの形状をプリント\n",
    "\n",
    "        memory = self.transformer_encoder(embedding_x_data, mask_x_data)\n",
    "        embedding_y_data = self.positional_encoding(self.token_embedding_y_data(y_data))\n",
    "        outs = self.transformer_decoder(embedding_y_data, memory, mask_y_data)\n",
    "        output = self.output(outs)\n",
    "        return output\n",
    "\n",
    "    def encode(self, x_data, mask_x_data):\n",
    "        return self.transformer_encoder(self.positional_encoding(self.token_embedding_x_data(x_data)), mask_x_data)\n",
    "\n",
    "    def decode(self, y_data, memory, mask_y_data):\n",
    "        return self.transformer_decoder(self.positional_encoding(self.token_embedding_y_data(y_data)), memory, mask_y_data)\n",
    "\n",
    "# マスクの定義\n",
    "def create_mask(x_data, y_data):\n",
    "    seq_len_x_data = x_data.shape[1]\n",
    "    seq_len_y_data = y_data.shape[1]\n",
    "    mask_y_data = generate_square_subsequent_mask(seq_len_y_data).to(device)\n",
    "    mask_x_data = generate_square_subsequent_mask(seq_len_x_data).to(device)\n",
    "    return mask_x_data, mask_y_data\n",
    "\n",
    "def generate_square_subsequent_mask(seq_len):\n",
    "    mask = torch.triu(torch.full((seq_len, seq_len), float('-inf')), diagonal=1)\n",
    "    return mask\n",
    "\n",
    "# 訓練、評価の処理を定義\n",
    "def train(model, data_provider, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    for x_data, y_data in data_provider:\n",
    "        x_data = x_data.float().to(device)\n",
    "        y_data = y_data.float().to(device)\n",
    "        input_y_data = torch.cat((x_data[:,-1:,:],y_data[:,:-1,:]), dim=1)\n",
    "        mask_x_data, mask_y_data = create_mask(x_data, input_y_data)\n",
    "        output = model(x_data=x_data, y_data=input_y_data, mask_x_data=mask_x_data, mask_y_data=mask_y_data)\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, y_data)\n",
    "        loss.backward()\n",
    "        total_loss.append(loss.cpu().detach())\n",
    "        optimizer.step()\n",
    "    return np.average(total_loss)\n",
    "\n",
    "def evaluate(flag, model, data_provider, criterion):\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    for x_data, y_data in data_provider:\n",
    "        x_data = x_data.float().to(device)\n",
    "        y_data = y_data.float().to(device)\n",
    "        seq_len_x_data = x_data.shape[1]\n",
    "        mask_x_data = (torch.zeros(seq_len_x_data, seq_len_x_data)).type(torch.bool)\n",
    "        mask_x_data = mask_x_data.float().to(device)\n",
    "        memory = model.encoderx_data, mask_x_data)\n",
    "        outputs = x_data[:, -1:, :]\n",
    "        seq_len_y_data = y_data.shape[1]\n",
    "        for i in range(seq_len_y_data - 1):\n",
    "            mask_y_data = (generate_square_subsequent_mask(outputs.size(1))).to(device)\n",
    "            output = model.decode(outputs, memory, mask_y_data)\n",
    "            output = model.output(output)\n",
    "            outputs = torch.cat([outputs, output[:, -1:, :]], dim=1)\n",
    "        loss = criterion(outputs, y_data)\n",
    "        total_loss.append(loss.cpu().detach())\n",
    "        all_true.append(torch.cat((x_data, y_data), dim=1).cpu().detach().numpy())\n",
    "        all_pred.append(torch.cat((x_data, outputs), dim=1).cpu().detach().numpy())\n",
    "    if flag == 'test':\n",
    "        true = np.concatenate(all_true)\n",
    "        pred = np.concatenate(all_pred)\n",
    "        df_true = pd.DataFrame(true.reshape(-1, 3), columns=['8_x', '8_y', '8_z'])\n",
    "        df_pred = pd.DataFrame(pred.reshape(-1, 3), columns=['8_x', '8_y', '8_z'])\n",
    "        df_true.to_csv('true_coordinates.csv', index=False)\n",
    "        df_pred.to_csv('predicted_coordinates.csv', index=False)\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(df_true['8_x'], label='true_x')\n",
    "        plt.plot(df_pred['8_x'], label='pred_x')\n",
    "        plt.plot(df_true['8_y'], label='true_y')\n",
    "        plt.plot(df_pred['8_y'], label='pred_y')\n",
    "        plt.plot(df_true['8_z'], label='true_z')\n",
    "        plt.plot(df_pred['8_z'], label='pred_z')\n",
    "        plt.legend()\n",
    "        plt.savefig('test_coordinates.pdf')\n",
    "    return np.average(total_loss)\n",
    "\n",
    "# パラメータなどの定義\n",
    "d_input = 3\n",
    "d_output = 3\n",
    "d_model = 512\n",
    "nhead = 8\n",
    "dim_feedforward = 2048\n",
    "num_encoder_layers = 1\n",
    "num_decoder_layers = 1\n",
    "dropout = 0.01\n",
    "x_data_len = 36\n",
    "y_data_len = 12\n",
    "batch_size = 1\n",
    "epochs = 30\n",
    "best_loss = float('Inf')\n",
    "best_model = None\n",
    "\n",
    "n_seq = 3\n",
    "num_joints = 21\n",
    "input_size = num_joints * 3\n",
    "hidden_size = 16\n",
    "output_size = num_joints * 3\n",
    "num_layers = 1\n",
    "batch_size = 36\n",
    "n_epochs = 100\n",
    "\n",
    "#print(\"Training and evaluating model\")\n",
    "\n",
    "print(\"モデルのトレーニングと評価を開始します\")\n",
    "\n",
    "train_csv_path = 'hand_300.csv'\n",
    "test_csv_path = 'test_10/choki_test_10/choki_test.csv'\n",
    "\n",
    "x_train, y_train = preprocess_data(train_csv_path, n_seq, num_joints)\n",
    "x_test, y_test = preprocess_data(test_csv_path, n_seq, num_joints)\n",
    "\n",
    "train_loader = create_dataloader(x_train, y_train, batch_size)\n",
    "\n",
    "model = Transformer(num_encoder_layers=num_encoder_layers, num_decoder_layers=num_decoder_layers, d_model=d_model, d_input=num_joints * 3, d_output=num_joints * 3, dim_feedforward=dim_feedforward, dropout=dropout, nhead=nhead)\n",
    "\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.RAdam(model.parameters(), lr=0.0001)\n",
    "\n",
    "valid_losses = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss_train = train(model=model, data_provider=data_provider('train', x_data_len, y_data_len, batch_size, feature='8_x'), optimizer=optimizer, criterion=criterion)\n",
    "    loss_valid = evaluate(flag='val', model=model, data_provider=data_provider('val', x_data_len, y_data_len, batch_size, feature='8_x'), criterion=criterion)\n",
    "    if epoch % 10 == 0:\n",
    "        print('[{}/{}] train loss: {:.2f}, valid loss: {:.2f}'.format(epoch, epochs, loss_train, loss_valid))\n",
    "    valid_losses.append(loss_valid)\n",
    "    if best_loss > loss_valid:\n",
    "        best_loss = loss_valid\n",
    "        best_model = model\n",
    "\n",
    "print(\"モデルのテストを開始します\")\n",
    "evaluate(flag='test', model=best_model, data_provider=data_provider('test', x_data_len, y_data_len, batch_size, feature='8_x'), criterion=criterion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Transformer_TimeSeriesForecasting-main-LRDpDuFD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
