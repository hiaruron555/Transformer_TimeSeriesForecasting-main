{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 273\u001b[0m\n\u001b[1;32m    268\u001b[0m         plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39maverage(total_loss)\n\u001b[1;32m    272\u001b[0m loss_train \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m--> 273\u001b[0m         model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m, data_provider\u001b[38;5;241m=\u001b[39mdata_provider(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, src_len, tgt_len, batch_size), optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m    274\u001b[0m         criterion\u001b[38;5;241m=\u001b[39mcriterion\n\u001b[1;32m    275\u001b[0m     )\n\u001b[1;32m    277\u001b[0m loss_valid \u001b[38;5;241m=\u001b[39m evaluate(\n\u001b[1;32m    278\u001b[0m         flag\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, model\u001b[38;5;241m=\u001b[39mmodel, data_provider\u001b[38;5;241m=\u001b[39mdata_provider(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m, src_len, tgt_len, batch_size), criterion\u001b[38;5;241m=\u001b[39mcriterion\n\u001b[1;32m    279\u001b[0m     )\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m epoch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m10\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "#【PyTorch】Transformerによる時系列予測\n",
    "#Library\n",
    "\n",
    "#ライブラリのインポート\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import LayerNorm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import TransformerEncoder, TransformerDecoder, TransformerEncoderLayer, TransformerDecoderLayer\n",
    "#from module_name import HandDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#ランダムシードの設定\n",
    "fix_seed = 2023\n",
    "np.random.seed(fix_seed)\n",
    "torch.manual_seed(fix_seed)\n",
    "\n",
    "#デバイスの設定\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#データのロードと実験用の整形\n",
    "\n",
    "class HandDataset(Dataset):\n",
    "    def __init__(self, flag, seq_len, pred_len):\n",
    "        #学習期間と予測期間の設定\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "        #訓練用、評価用、テスト用を分けるためのフラグ\n",
    "        type_map = {'train': 0, 'val': 1, 'test':2}\n",
    "        self.set_type = type_map[flag]\n",
    "\n",
    "        self.__read_data__()\n",
    "\n",
    "    def __read_data__(self):\n",
    "        \n",
    "        df_raw = pd.read_csv('hand_300.csv')\n",
    "        self.labels = df_raw['hand'].unique()\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        df_raw['hand'] = self.label_encoder.fit_transform(df_raw['hand'])\n",
    "\n",
    "        data = df_raw.drop(columns=['hand']).values\n",
    "        self.targets = df_raw[['hand']].values\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        data = ss.fit_transform(data)\n",
    "\n",
    "        border1s = [0, int(0.7 * len(data)), int(0.9 * len(data))]\n",
    "        border2s = [int(0.7 * len(data)), int(0.9 * len(data)), len(data)]\n",
    "        border1 = border1s[self.set_type]\n",
    "        border2 = border2s[self.set_type]\n",
    "\n",
    "        self.data = data[border1:border2]\n",
    "        self.targets = self.targets[border1:border2]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #学習用の系列と予測用の系列を出力\n",
    "        s_begin = index\n",
    "        s_end = s_begin + self.seq_len\n",
    "        r_begin = s_end\n",
    "        r_end = r_begin + self.pred_len\n",
    "\n",
    "        src = self.data[s_begin:s_end]\n",
    "        tgt = self.targets[r_begin:r_end]\n",
    "\n",
    "        return src, tgt\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.seq_len - self.pred_len + 1\n",
    "\n",
    "#DataLoaderの定義\n",
    "\n",
    "def data_provider(flag, seq_len, pred_len, batch_size):\n",
    "    dataset = HandDataset(flag=flag, seq_len=seq_len, pred_len=pred_len)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#エンべディングの定義\n",
    "\n",
    "#位置エンコーディングの定義\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "#モデルに入力するために次元を拡張する\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, c_in, d_model):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.tokenConv = nn.Linear(c_in, d_model) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.tokenConv(x)\n",
    "        return x\n",
    "\n",
    "#Transformerの定義\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers, num_decoder_layers,\n",
    "        d_model, d_input, d_output,\n",
    "        dim_feedforward = 512, dropout = 0.1, nhead = 8):\n",
    "        \n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "\n",
    "        #エンべディングの定義\n",
    "        self.token_embedding_src = TokenEmbedding(d_input, d_model)\n",
    "        self.token_embedding_tgt = TokenEmbedding(d_output, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout=dropout)\n",
    "        \n",
    "        #エンコーダの定義\n",
    "        encoder_layer = TransformerEncoderLayer(d_model=d_model, \n",
    "                                                nhead=nhead, \n",
    "                                                dim_feedforward=dim_feedforward,\n",
    "                                                dropout=dropout,\n",
    "                                                batch_first=True,\n",
    "                                                activation='gelu'\n",
    "                                               )\n",
    "        encoder_norm = LayerNorm(d_model)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, \n",
    "                                                      num_layers=num_encoder_layers,\n",
    "                                                      norm=encoder_norm\n",
    "                                                     )\n",
    "        \n",
    "        #デコーダの定義\n",
    "        decoder_layer = TransformerDecoderLayer(d_model=d_model, \n",
    "                                                nhead=nhead, \n",
    "                                                dim_feedforward=dim_feedforward,\n",
    "                                                dropout=dropout,\n",
    "                                                batch_first=True,\n",
    "                                                activation='gelu'\n",
    "                                               )\n",
    "        decoder_norm = LayerNorm(d_model)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, \n",
    "                                                      num_layers=num_decoder_layers, \n",
    "                                                      norm=decoder_norm)\n",
    "        \n",
    "        #出力層の定義\n",
    "        self.output = nn.Linear(d_model, d_output)\n",
    "        \n",
    "\n",
    "    def forward(self, src, tgt, mask_src, mask_tgt):\n",
    "        #mask_src, mask_tgtはセルフアテンションの際に未来のデータにアテンションを向けないためのマスク\n",
    "        \n",
    "        embedding_src = self.positional_encoding(self.token_embedding_src(src))\n",
    "        memory = self.transformer_encoder(embedding_src, mask_src)\n",
    "        \n",
    "        embedding_tgt = self.positional_encoding(self.token_embedding_tgt(tgt))\n",
    "        outs = self.transformer_decoder(embedding_tgt, memory, mask_tgt)\n",
    "        \n",
    "        output = self.output(outs)\n",
    "        return output\n",
    "\n",
    "    def encode(self, src, mask_src):\n",
    "        return self.transformer_encoder(self.positional_encoding(self.token_embedding_src(src)), mask_src)\n",
    "\n",
    "    def decode(self, tgt, memory, mask_tgt):\n",
    "        return self.transformer_decoder(self.positional_encoding(self.token_embedding_tgt(tgt)), memory, mask_tgt)\n",
    "\n",
    "#マスクの定義\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    \n",
    "    seq_len_src = src.shape[1]\n",
    "    seq_len_tgt = tgt.shape[1]\n",
    "\n",
    "    mask_tgt = generate_square_subsequent_mask(seq_len_tgt).to(device)\n",
    "    mask_src = generate_square_subsequent_mask(seq_len_src).to(device)\n",
    "\n",
    "    return mask_src, mask_tgt\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(seq_len):\n",
    "    mask = torch.triu(torch.full((seq_len, seq_len), float('-inf')), diagonal=1)\n",
    "    return mask\n",
    "\n",
    "#訓練、評価の処理を定義\n",
    "\n",
    "def train(model, data_provider, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    for src, tgt in data_provider:\n",
    "        \n",
    "        src = src.float().to(device)\n",
    "        tgt = tgt.float().to(device)\n",
    "\n",
    "        input_tgt = torch.cat((src[:,-1:,:],tgt[:,:-1,:]), dim=1)\n",
    "\n",
    "        print(f'src shape: {src.shape}, tgt shape: {tgt.shape}')  # デバッグ用出力\n",
    "\n",
    "        mask_src, mask_tgt = create_mask(src, input_tgt)\n",
    "\n",
    "        print(f'input_tgt shape: {input_tgt.shape}')  # デバッグ用出力\n",
    "\n",
    "        output = model(\n",
    "            src=src, tgt=input_tgt, \n",
    "            mask_src=mask_src, mask_tgt=mask_tgt\n",
    "        )\n",
    "\n",
    "        print(f'output shape: {output.shape}')  # デバッグ用出力\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output, tgt)\n",
    "        loss.backward()\n",
    "        total_loss.append(loss.cpu().detach())\n",
    "        optimizer.step()\n",
    "        \n",
    "    return np.average(total_loss)\n",
    "\n",
    "\n",
    "def evaluate(flag, model, data_provider, criterion):\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    for src, tgt in data_provider:\n",
    "        \n",
    "        src = src.float().to(device)\n",
    "        tgt = tgt.float().to(device)\n",
    "\n",
    "        seq_len_src = src.shape[1]\n",
    "        mask_src = (torch.zeros(seq_len_src, seq_len_src)).type(torch.bool)\n",
    "        mask_src = mask_src.float().to(device)\n",
    "        \n",
    "        memory = model.encode(src, mask_src)\n",
    "        outputs = src[:, -1:, :]\n",
    "        seq_len_tgt = tgt.shape[1]\n",
    "        \n",
    "        for i in range(seq_len_tgt - 1):\n",
    "        \n",
    "            mask_tgt = (generate_square_subsequent_mask(outputs.size(1))).to(device)\n",
    "        \n",
    "            output = model.decode(outputs, memory, mask_tgt)\n",
    "            output = model.output(output)\n",
    "\n",
    "            outputs = torch.cat([outputs, output[:, -1:, :]], dim=1)\n",
    "        \n",
    "            loss = criterion(outputs, tgt)\n",
    "            total_loss.append(loss.cpu().detach())\n",
    "        \n",
    "    if flag=='test':\n",
    "        true = torch.cat((src, tgt), dim=1)\n",
    "        pred = torch.cat((outputs[:, :-1, :], output[:, -tgt_len:, :]), dim=1)  # Fix: Ensure the dimensions of tensors being concatenated are compatible\n",
    "        plt.plot(true.squeeze().cpu().detach().numpy(), label='true')\n",
    "        plt.plot(pred.squeeze().cpu().detach().numpy(), label='pred')\n",
    "        plt.legend()\n",
    "        plt.savefig('test.pdf')\n",
    "        \n",
    "    return np.average(total_loss)\n",
    "\n",
    "loss_train = train(\n",
    "        model=model, data_provider=data_provider('train', src_len, tgt_len, batch_size), optimizer=optimizer,\n",
    "        criterion=criterion\n",
    "    )\n",
    "        \n",
    "loss_valid = evaluate(\n",
    "        flag='val', model=model, data_provider=data_provider('val', src_len, tgt_len, batch_size), criterion=criterion\n",
    "    )\n",
    "    \n",
    "if epoch%10==0:\n",
    "        print('[{}/{}] train loss: {:.2f}, valid loss: {:.2f}'.format(\n",
    "            epoch, epochs,\n",
    "            loss_train, loss_valid,\n",
    "        ))\n",
    "        \n",
    "valid_losses.append(loss_valid)\n",
    "    \n",
    "if best_loss > loss_valid:\n",
    "        best_loss = loss_valid\n",
    "        best_model = model\n",
    "\n",
    "\n",
    "#テスト用データにおける予測\n",
    "\n",
    "evaluate(flag='test', model=best_model, data_provider=data_provider('test', src_len, tgt_len, batch_size), criterion=criterion)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
